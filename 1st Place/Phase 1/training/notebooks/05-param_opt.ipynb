{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4c9e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from catboost import CatBoostRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb98c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "airport = 'KMEM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b78ee5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_parquet(f'../data/05_model_input/master_{airport.lower()}.pq')\n",
    "target_name = 'minutes_until_pushback'\n",
    "end_train = \"2022-09-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c131149",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################     training with  (1275303, 294)      ####################\n",
      "####################     validating with  (80802, 294)      ####################\n",
      "0:\tlearn: 20.8236633\ttest: 14.8924156\tbest: 14.8924156 (0)\ttotal: 1.82s\tremaining: 10h 6m 12s\n",
      "50:\tlearn: 19.8125660\ttest: 14.1333130\tbest: 14.1333130 (50)\ttotal: 1m 12s\tremaining: 7h 51m 34s\n",
      "100:\tlearn: 19.1505934\ttest: 13.6444781\tbest: 13.6444781 (100)\ttotal: 2m 23s\tremaining: 7h 50m 46s\n",
      "150:\tlearn: 18.7093672\ttest: 13.3446349\tbest: 13.3446349 (150)\ttotal: 3m 34s\tremaining: 7h 49m 52s\n",
      "200:\tlearn: 18.3906932\ttest: 13.1205332\tbest: 13.1205332 (200)\ttotal: 4m 50s\tremaining: 7h 56m 39s\n",
      "250:\tlearn: 18.1473011\ttest: 12.9468761\tbest: 12.9468761 (250)\ttotal: 6m 8s\tremaining: 8h 3m 34s\n",
      "300:\tlearn: 17.9559431\ttest: 12.7855669\tbest: 12.7855669 (300)\ttotal: 7m 27s\tremaining: 8h 8m 26s\n",
      "350:\tlearn: 17.8032214\ttest: 12.6742701\tbest: 12.6742701 (350)\ttotal: 8m 58s\tremaining: 8h 22m 14s\n",
      "400:\tlearn: 17.6719252\ttest: 12.5831149\tbest: 12.5831149 (400)\ttotal: 10m 24s\tremaining: 8h 28m 35s\n",
      "450:\tlearn: 17.5565182\ttest: 12.5016095\tbest: 12.5016095 (450)\ttotal: 11m 46s\tremaining: 8h 30m 11s\n",
      "500:\tlearn: 17.4539360\ttest: 12.4363970\tbest: 12.4363970 (500)\ttotal: 13m 12s\tremaining: 8h 34m\n",
      "550:\tlearn: 17.3696623\ttest: 12.3805734\tbest: 12.3805734 (550)\ttotal: 14m 42s\tremaining: 8h 39m 4s\n",
      "600:\tlearn: 17.2960291\ttest: 12.3343705\tbest: 12.3343705 (600)\ttotal: 16m 4s\tremaining: 8h 39m 5s\n",
      "650:\tlearn: 17.2246967\ttest: 12.3033270\tbest: 12.3033270 (650)\ttotal: 17m 28s\tremaining: 8h 39m 30s\n",
      "700:\tlearn: 17.1594906\ttest: 12.2676099\tbest: 12.2676099 (700)\ttotal: 19m 3s\tremaining: 8h 44m 48s\n",
      "750:\tlearn: 17.0982879\ttest: 12.2307314\tbest: 12.2307314 (750)\ttotal: 20m 36s\tremaining: 8h 48m 1s\n",
      "800:\tlearn: 17.0444124\ttest: 12.1984166\tbest: 12.1984166 (800)\ttotal: 22m 5s\tremaining: 8h 49m 29s\n",
      "850:\tlearn: 16.9941387\ttest: 12.1713669\tbest: 12.1713669 (850)\ttotal: 23m 35s\tremaining: 8h 50m 56s\n",
      "900:\tlearn: 16.9482342\ttest: 12.1455920\tbest: 12.1455920 (900)\ttotal: 25m 1s\tremaining: 8h 50m 22s\n",
      "950:\tlearn: 16.9035175\ttest: 12.1190687\tbest: 12.1190687 (950)\ttotal: 26m 39s\tremaining: 8h 53m 56s\n",
      "1000:\tlearn: 16.8624564\ttest: 12.0967417\tbest: 12.0967417 (1000)\ttotal: 28m 1s\tremaining: 8h 52m 1s\n",
      "1050:\tlearn: 16.8230487\ttest: 12.0738404\tbest: 12.0738404 (1050)\ttotal: 29m 24s\tremaining: 8h 50m 20s\n",
      "1100:\tlearn: 16.7867422\ttest: 12.0592897\tbest: 12.0592897 (1100)\ttotal: 30m 52s\tremaining: 8h 49m 58s\n",
      "1150:\tlearn: 16.7512603\ttest: 12.0432878\tbest: 12.0432878 (1150)\ttotal: 32m 20s\tremaining: 8h 49m 31s\n",
      "1200:\tlearn: 16.7191237\ttest: 12.0311890\tbest: 12.0311890 (1200)\ttotal: 33m 44s\tremaining: 8h 48m 1s\n",
      "1250:\tlearn: 16.6873246\ttest: 12.0190372\tbest: 12.0189729 (1248)\ttotal: 35m 10s\tremaining: 8h 47m 10s\n",
      "1300:\tlearn: 16.6574760\ttest: 12.0103059\tbest: 12.0099578 (1295)\ttotal: 36m 39s\tremaining: 8h 46m 56s\n",
      "1350:\tlearn: 16.6294506\ttest: 12.0027397\tbest: 12.0027397 (1350)\ttotal: 38m 5s\tremaining: 8h 45m 48s\n",
      "1400:\tlearn: 16.6026312\ttest: 11.9942712\tbest: 11.9942712 (1400)\ttotal: 39m 34s\tremaining: 8h 45m 22s\n",
      "1450:\tlearn: 16.5775351\ttest: 11.9880015\tbest: 11.9874574 (1445)\ttotal: 41m 3s\tremaining: 8h 44m 46s\n",
      "1500:\tlearn: 16.5533525\ttest: 11.9787964\tbest: 11.9787964 (1500)\ttotal: 42m 37s\tremaining: 8h 45m 22s\n",
      "1550:\tlearn: 16.5290882\ttest: 11.9717894\tbest: 11.9717894 (1550)\ttotal: 44m 4s\tremaining: 8h 44m 15s\n",
      "1600:\tlearn: 16.5057659\ttest: 11.9670928\tbest: 11.9670928 (1600)\ttotal: 45m 32s\tremaining: 8h 43m 22s\n",
      "1650:\tlearn: 16.4839015\ttest: 11.9620133\tbest: 11.9617120 (1649)\ttotal: 46m 59s\tremaining: 8h 42m 18s\n",
      "1700:\tlearn: 16.4617991\ttest: 11.9563476\tbest: 11.9563476 (1700)\ttotal: 48m 22s\tremaining: 8h 40m 28s\n",
      "1750:\tlearn: 16.4409906\ttest: 11.9513966\tbest: 11.9513966 (1750)\ttotal: 49m 53s\tremaining: 8h 39m 54s\n",
      "1800:\tlearn: 16.4210385\ttest: 11.9488197\tbest: 11.9484440 (1796)\ttotal: 51m 15s\tremaining: 8h 37m 52s\n",
      "1850:\tlearn: 16.4034371\ttest: 11.9453447\tbest: 11.9453447 (1850)\ttotal: 52m 44s\tremaining: 8h 37m 3s\n",
      "1900:\tlearn: 16.3848566\ttest: 11.9402795\tbest: 11.9401500 (1899)\ttotal: 54m 12s\tremaining: 8h 36m 4s\n",
      "1950:\tlearn: 16.3663133\ttest: 11.9357284\tbest: 11.9357284 (1950)\ttotal: 55m 36s\tremaining: 8h 34m 28s\n",
      "2000:\tlearn: 16.3481767\ttest: 11.9340380\tbest: 11.9339344 (1983)\ttotal: 57m 4s\tremaining: 8h 33m 21s\n",
      "2050:\tlearn: 16.3315650\ttest: 11.9295921\tbest: 11.9295921 (2050)\ttotal: 58m 30s\tremaining: 8h 32m 5s\n",
      "2100:\tlearn: 16.3157266\ttest: 11.9270063\tbest: 11.9267327 (2095)\ttotal: 1h 4s\tremaining: 8h 31m 47s\n",
      "2150:\tlearn: 16.3004363\ttest: 11.9220903\tbest: 11.9220903 (2150)\ttotal: 1h 1m 29s\tremaining: 8h 30m 17s\n",
      "2200:\tlearn: 16.2844857\ttest: 11.9182912\tbest: 11.9182912 (2200)\ttotal: 1h 2m 55s\tremaining: 8h 28m 53s\n",
      "2250:\tlearn: 16.2695857\ttest: 11.9150881\tbest: 11.9150881 (2250)\ttotal: 1h 4m 21s\tremaining: 8h 27m 31s\n",
      "2300:\tlearn: 16.2553462\ttest: 11.9148201\tbest: 11.9140227 (2283)\ttotal: 1h 5m 48s\tremaining: 8h 26m 8s\n",
      "2350:\tlearn: 16.2410619\ttest: 11.9124812\tbest: 11.9124812 (2350)\ttotal: 1h 7m 13s\tremaining: 8h 24m 37s\n",
      "2400:\tlearn: 16.2266208\ttest: 11.9100427\tbest: 11.9095882 (2382)\ttotal: 1h 8m 37s\tremaining: 8h 23m 1s\n",
      "2450:\tlearn: 16.2134929\ttest: 11.9078717\tbest: 11.9076307 (2446)\ttotal: 1h 10m 2s\tremaining: 8h 21m 31s\n",
      "2500:\tlearn: 16.1991180\ttest: 11.9052950\tbest: 11.9052751 (2494)\ttotal: 1h 11m 26s\tremaining: 8h 19m 53s\n",
      "2550:\tlearn: 16.1857169\ttest: 11.9041080\tbest: 11.9038115 (2546)\ttotal: 1h 12m 50s\tremaining: 8h 18m 14s\n",
      "2600:\tlearn: 16.1733260\ttest: 11.9022421\tbest: 11.9020108 (2584)\ttotal: 1h 14m 15s\tremaining: 8h 16m 42s\n",
      "2650:\tlearn: 16.1610390\ttest: 11.9012712\tbest: 11.9009906 (2637)\ttotal: 1h 15m 40s\tremaining: 8h 15m 12s\n",
      "2700:\tlearn: 16.1493828\ttest: 11.8980385\tbest: 11.8978991 (2697)\ttotal: 1h 17m 6s\tremaining: 8h 13m 51s\n",
      "2750:\tlearn: 16.1379033\ttest: 11.8958674\tbest: 11.8958674 (2750)\ttotal: 1h 18m 34s\tremaining: 8h 12m 41s\n",
      "2800:\tlearn: 16.1265700\ttest: 11.8925197\tbest: 11.8925197 (2800)\ttotal: 1h 20m 2s\tremaining: 8h 11m 29s\n",
      "2850:\tlearn: 16.1151941\ttest: 11.8902479\tbest: 11.8899888 (2844)\ttotal: 1h 21m 38s\tremaining: 8h 11m 2s\n",
      "2900:\tlearn: 16.1031764\ttest: 11.8883360\tbest: 11.8881340 (2899)\ttotal: 1h 23m 4s\tremaining: 8h 9m 39s\n",
      "2950:\tlearn: 16.0914720\ttest: 11.8871853\tbest: 11.8867865 (2927)\ttotal: 1h 24m 52s\tremaining: 8h 10m 21s\n",
      "3000:\tlearn: 16.0799159\ttest: 11.8846576\tbest: 11.8845356 (2994)\ttotal: 1h 26m 31s\tremaining: 8h 10m 7s\n",
      "3050:\tlearn: 16.0687594\ttest: 11.8826384\tbest: 11.8822630 (3037)\ttotal: 1h 28m 24s\tremaining: 8h 11m 8s\n",
      "3100:\tlearn: 16.0578074\ttest: 11.8812798\tbest: 11.8812161 (3099)\ttotal: 1h 30m 4s\tremaining: 8h 10m 49s\n",
      "3150:\tlearn: 16.0467595\ttest: 11.8788260\tbest: 11.8788260 (3150)\ttotal: 1h 31m 28s\tremaining: 8h 9m 5s\n",
      "3200:\tlearn: 16.0370002\ttest: 11.8774536\tbest: 11.8771425 (3181)\ttotal: 1h 32m 54s\tremaining: 8h 7m 33s\n",
      "3250:\tlearn: 16.0263473\ttest: 11.8758170\tbest: 11.8758170 (3250)\ttotal: 1h 34m 20s\tremaining: 8h 6m 2s\n",
      "3300:\tlearn: 16.0155858\ttest: 11.8752705\tbest: 11.8748617 (3297)\ttotal: 1h 35m 48s\tremaining: 8h 4m 40s\n",
      "3350:\tlearn: 16.0057029\ttest: 11.8752337\tbest: 11.8748617 (3297)\ttotal: 1h 37m 11s\tremaining: 8h 2m 54s\n",
      "Stopped by overfitting detector  (60 iterations wait)\n",
      "\n",
      "bestTest = 11.87486168\n",
      "bestIteration = 3297\n",
      "\n",
      "Shrink model to first 3298 iterations.\n",
      "11.874861681265541\n",
      "{'eta': 0.005, 'depth': 7, 'rsm': 0.7}\n",
      "0:\tlearn: 20.8251010\ttest: 14.8940744\tbest: 14.8940744 (0)\ttotal: 2.09s\tremaining: 11h 35m 25s\n",
      "50:\tlearn: 19.8266508\ttest: 14.1312262\tbest: 14.1312262 (50)\ttotal: 1m 41s\tremaining: 11h 1m 21s\n",
      "100:\tlearn: 19.1499857\ttest: 13.6379909\tbest: 13.6379909 (100)\ttotal: 3m 20s\tremaining: 10h 58m 45s\n",
      "150:\tlearn: 18.7028601\ttest: 13.3401095\tbest: 13.3401095 (150)\ttotal: 5m 6s\tremaining: 11h 12m 11s\n",
      "200:\tlearn: 18.3885182\ttest: 13.1144333\tbest: 13.1144333 (200)\ttotal: 6m 58s\tremaining: 11h 27m 20s\n",
      "250:\tlearn: 18.1450875\ttest: 12.9387472\tbest: 12.9387472 (250)\ttotal: 8m 56s\tremaining: 11h 43m 9s\n"
     ]
    }
   ],
   "source": [
    "x = x[(x['timestamp'] > '2020-11-02') & (x[target_name] != 0)]\n",
    "\n",
    "feat_names = list(x.columns)\n",
    "feat_names.remove(\"gufi\")\n",
    "feat_names.remove(\"timestamp\")\n",
    "feat_names.remove(target_name)\n",
    "\n",
    "cat_features = [i for i in range(len(feat_names)) if '_cat_' in feat_names[i]]\n",
    "\n",
    "x_train = x[x[\"timestamp\"] < end_train][feat_names]\n",
    "y_train = x[x[\"timestamp\"] < end_train][target_name] - x_train['etd_time_till_est_dep']\n",
    "x_val = x[x[\"timestamp\"] >= end_train][feat_names]\n",
    "y_val = x[x[\"timestamp\"] >= end_train][target_name] - x_val['etd_time_till_est_dep']\n",
    "\n",
    "print(\"#\" * 20 + ' ' * 5 + \"training with \", x_train.shape, ' ' * 5 + '#' * 20)\n",
    "print(\"#\" * 20 + ' ' * 5 + \"validating with \", x_val.shape, ' ' * 5 + '#' * 20)\n",
    "\n",
    "\n",
    "best_params = None\n",
    "best_score = 1e9\n",
    "\n",
    "for eta in [0.005, 0.01, 0.03]:\n",
    "    for depth in [7, 9, 11]:\n",
    "        for rsm in [0.7, 0.9, 1]:\n",
    "\n",
    "            model = CatBoostRegressor(eta=eta,\n",
    "                                      depth=depth,\n",
    "                                      rsm=rsm,\n",
    "                                      max_leaves=21,\n",
    "                                      l2_leaf_reg=5,\n",
    "                                      min_data_in_leaf=5000,\n",
    "                                      n_estimators=20000,\n",
    "                                      task_type='CPU',\n",
    "                                      thread_count=-1,\n",
    "                                      grow_policy='Lossguide',\n",
    "                                      has_time=True,\n",
    "                                      random_seed=4,\n",
    "                                      loss_function='MAE',\n",
    "                                      boosting_type='Plain',\n",
    "                                      max_ctr_complexity=12,\n",
    "                                      bootstrap_type='Bernoulli',\n",
    "                                      subsample=0.8)\n",
    "\n",
    "            model.fit(x_train, y_train,\n",
    "                      eval_set=(x_val, y_val),\n",
    "                      use_best_model=True,\n",
    "                      verbose=50,\n",
    "                      cat_features=cat_features,\n",
    "                      early_stopping_rounds=60)\n",
    "            \n",
    "            if model.best_score_['validation']['MAE'] < best_score:\n",
    "                best_score = model.best_score_['validation']['MAE']\n",
    "                best_params = {'eta': eta, 'depth': depth, 'rsm': rsm}\n",
    "                print(best_score)\n",
    "                print(best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
