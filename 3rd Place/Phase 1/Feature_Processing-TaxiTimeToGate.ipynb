{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60b72af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None\n",
    "from helper import data_loader, data_loader_train_labels, split_gufi, extract_taxi_to_gate_time,  data_loader_submission_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b315987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the following dir: Inference_Extracted_Features/features_1682574327.6379874/\n"
     ]
    }
   ],
   "source": [
    "bool_submission_prep = 1\n",
    "\n",
    "# Define the directory path for loading data\n",
    "load_dir = \"Data/\"\n",
    "\n",
    "# Set the save directory based on whether we are preparing for submission or not\n",
    "if bool_submission_prep:\n",
    "    sav_dir = f\"Inference_Extracted_Features/taxitime_to_gate_{time.time()}/\"\n",
    "else:\n",
    "    sav_dir = f\"Training_Extracted_Features/taxitime_to_gate_{time.time()}/\"\n",
    "\n",
    "# Create the save directory\n",
    "os.mkdir(f\"{sav_dir}\")\n",
    "\n",
    "# Print the created directory path\n",
    "print(f'Created the following dir: {sav_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29f60cb1-d282-4eae-86b7-8aaa1e69111c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Doing airport: KATL\n",
      "Loading in dataframes for: KATL\n",
      "LOading from: Data/submission_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4817/4817 [00:07<00:00, 616.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Doing airport: KCLT\n",
      "Loading in dataframes for: KCLT\n",
      "LOading from: Data/submission_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4462/4462 [00:05<00:00, 788.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Doing airport: KDEN\n",
      "Loading in dataframes for: KDEN\n",
      "LOading from: Data/submission_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5013/5013 [00:07<00:00, 712.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Doing airport: KDFW\n",
      "Loading in dataframes for: KDFW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/Projects/PredictPushBackTimes_US/NASA-Final-Submission 2/NASA-Final-Submission/helper.py:245: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_mfs = pd.read_csv(f\"{directory}{airport}/{airport}/{airport}_mfs.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOading from: Data/submission_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4916/4916 [00:08<00:00, 601.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Doing airport: KJFK\n",
      "Loading in dataframes for: KJFK\n",
      "LOading from: Data/submission_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4638/4638 [00:03<00:00, 1174.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Doing airport: KMEM\n",
      "Loading in dataframes for: KMEM\n",
      "LOading from: Data/submission_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4906/4906 [00:04<00:00, 1138.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Doing airport: KMIA\n",
      "Loading in dataframes for: KMIA\n",
      "LOading from: Data/submission_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4765/4765 [00:04<00:00, 1063.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Doing airport: KORD\n",
      "Loading in dataframes for: KORD\n",
      "LOading from: Data/submission_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4670/4670 [00:06<00:00, 694.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Doing airport: KPHX\n",
      "Loading in dataframes for: KPHX\n",
      "LOading from: Data/submission_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4963/4963 [00:05<00:00, 909.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Doing airport: KSEA\n",
      "Loading in dataframes for: KSEA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/Projects/PredictPushBackTimes_US/NASA-Final-Submission 2/NASA-Final-Submission/helper.py:245: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_mfs = pd.read_csv(f\"{directory}{airport}/{airport}/{airport}_mfs.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOading from: Data/submission_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4880/4880 [00:05<00:00, 935.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define the list of airport codes to process\n",
    "list_airports = [\"KATL\", \"KCLT\", \"KDEN\", \"KDFW\", \"KJFK\", \"KMEM\", \"KMIA\", \"KORD\", \"KPHX\", \"KSEA\"]\n",
    "\n",
    "# Process each airport in the list\n",
    "for airport in list_airports:\n",
    "    airport_short = airport[-3:]\n",
    "    print(f'-----------------------------')\n",
    "    print(f'Doing airport: {airport}')\n",
    "\n",
    "    # Load data for the current airport\n",
    "    print(f'Loading in dataframes for: {airport}')\n",
    "    df_config, df_etd, df_first_pos, df_lamp, df_mfs, df_runway_arrival, df_runway_departure, df_standtimes = data_loader(load_dir, airport)\n",
    "    if bool_submission_prep:\n",
    "        df_train_labels = data_loader_submission_train_labels(load_dir, airport)\n",
    "    else:\n",
    "        df_train_labels = data_loader_train_labels(load_dir, airport)\n",
    "\n",
    "    # Filter out unnecessary rows from the ETD dataframe\n",
    "    df_etd_shorter = df_etd[df_etd.timestamp < df_etd.departure_runway_estimated_time]\n",
    "    unique_timestamps = df_train_labels.timestamp.unique()\n",
    "    df_standtimes = split_gufi(df_standtimes)\n",
    "\n",
    "    # Create copies of the dataframes to work with\n",
    "    df_train_labels_copy = df_train_labels.copy(deep=True)\n",
    "\n",
    "    df_runway_arrival_copy = df_runway_arrival.copy(deep=True)\n",
    "    df_runway_arrival_copy['arrival_runway_actual_time'] = pd.to_datetime(df_runway_arrival_copy['arrival_runway_actual_time'])\n",
    "    df_runway_arrival_copy = df_runway_arrival_copy.sort_values(by='timestamp')\n",
    "    df_runway_arrival_copy.rename(columns={\"timestamp\":'timestamp_runway_arrival'}, inplace=True)\n",
    "\n",
    "    df_standtimes_copy = df_standtimes.copy(deep=True)\n",
    "    df_standtimes_copy = df_standtimes_copy.sort_values(by='timestamp')\n",
    "    df_standtimes_copy.rename(columns={\"timestamp\":'timestamp_standtimes'}, inplace=True)\n",
    "\n",
    "    # Filter standtimes to keep only the arriving planes at the current airport\n",
    "    df_standtimes_copy = df_standtimes_copy[df_standtimes_copy.arriving_airport_code == airport_short]\n",
    "    cols_to_use = list(df_standtimes_copy.columns.difference(df_runway_arrival_copy.columns))\n",
    "    cols_to_use.insert(0, 'gufi')\n",
    "    df_arrival_standtimes = df_standtimes_copy[cols_to_use].merge(df_runway_arrival_copy, on=['gufi'], how='left')\n",
    "    df_arrival_standtimes['taxitime_to_gate'] = (df_arrival_standtimes.arrival_stand_actual_time - df_arrival_standtimes.arrival_runway_actual_time).dt.total_seconds().values / 60\n",
    "    df_arrival_standtimes.dropna(inplace=True)\n",
    "\n",
    "    # Iterate through unique timestamps and extract taxi time to gate data\n",
    "    unique_list_timestamps = df_train_labels.sort_values(by=\"timestamp\").timestamp.unique()\n",
    "    results = []\n",
    "    timestamps = []\n",
    "    for each in tqdm(unique_list_timestamps):\n",
    "        each = pd.Timestamp(each)\n",
    "        result = np.array(extract_taxi_to_gate_time(each, df_arrival_standtimes))\n",
    "        timestamps.append(each)\n",
    "        results.append(result)\n",
    "        \n",
    "    # Create a dataframe with taxi time to gate statistics\n",
    "    taxitime_to_gate_df = pd.DataFrame(columns=['timestamp', 'found_counts_taxitime_to_gate', 'taxitime_to_gate_mean', 'taxitime_to_gate_std'])\n",
    "    taxitime_to_gate_df['timestamp'] = timestamps\n",
    "    taxitime_to_gate_df[['found_counts_taxitime_to_gate', 'taxitime_to_gate_mean', 'taxitime_to_gate_std']] = np.array(results)\n",
    "\n",
    "    # Filter out rows with no taxi time to gate data\n",
    "    taxitime_to_gate_df = taxitime_to_gate_df[taxitime_to_gate_df.found_counts_taxitime_to_gate != 0]\n",
    "\n",
    "    # Save the extracted taxi time to gate data to a CSV file\n",
    "    etd_sav_path = f\"{sav_dir}timepoint_{airport}_taxitime_to_gate.csv\"\n",
    "    taxitime_to_gate_df.to_csv(etd_sav_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ca141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pushback_plane_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
